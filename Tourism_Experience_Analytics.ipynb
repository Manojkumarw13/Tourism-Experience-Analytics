{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "collapsed_sections": [
    "vncDsAP0Gaoa",
    "FJNUwmbgGyua",
    "w6K7xa23Elo4",
    "yQaldy8SH6Dl",
    "mDgbUHAGgjLW",
    "O_i_v8NEhb9l",
    "HhfV-JJviCcP",
    "Y3lxredqlCYt",
    "3RnN4peoiCZX",
    "x71ZqKXriCWQ",
    "7hBIi_osiCS2",
    "JlHwYmJAmNHm",
    "35m5QtbWiB9F",
    "PoPl-ycgm1ru",
    "H0kj-8xxnORC",
    "nA9Y7ga8ng1Z",
    "PBTbrJXOngz2",
    "u3PMJOP6ngxN",
    "dauF4eBmngu3",
    "bKJF3rekwFvQ",
    "MSa1f5Uengrz",
    "GF8Ens_Soomf",
    "0wOQAZs5pc--",
    "K5QZ13OEpz2H",
    "lQ7QKXXCp7Bj",
    "448CDAPjqfQr",
    "KSlN3yHqYklG",
    "t6dVpIINYklI",
    "ijmpgYnKYklI",
    "-JiQyfWJYklI",
    "EM7whBJCYoAo",
    "fge-S5ZAYoAp",
    "85gYPyotYoAp",
    "RoGjAbkUYoAp",
    "4Of9eVA-YrdM",
    "iky9q4vBYrdO",
    "F6T5p64dYrdO",
    "y-Ehk30pYrdP",
    "bamQiAODYuh1",
    "QHF8YVU7Yuh3",
    "GwzvFGzlYuh3",
    "qYpmQ266Yuh3",
    "OH-pJp9IphqM",
    "bbFf2-_FphqN",
    "_ouA3fa0phqN",
    "Seke61FWphqN",
    "PIIx-8_IphqN",
    "t27r6nlMphqO",
    "r2jJGEOYphqO",
    "b0JNsNcRphqO",
    "BZR9WyysphqO",
    "jj7wYXLtphqO",
    "eZrbJ2SmphqO",
    "rFu4xreNphqO",
    "YJ55k-q6phqO",
    "gCFgpxoyphqP",
    "OVtJsKN_phqQ",
    "lssrdh5qphqQ",
    "U2RJ9gkRphqQ",
    "1M8mcRywphqQ",
    "tgIPom80phqQ",
    "JMzcOPDDphqR",
    "x-EpHcCOp1ci",
    "X_VqEhTip1ck",
    "8zGJKyg5p1ck",
    "PVzmfK_Ep1ck",
    "n3dbpmDWp1ck",
    "ylSl6qgtp1ck",
    "ZWILFDl5p1ck",
    "M7G43BXep1ck",
    "Ag9LCva-p1cl",
    "E6MkPsBcp1cl",
    "2cELzS2fp1cl",
    "3MPXvC8up1cl",
    "NC_X3p0fY2L0",
    "UV0SzAkaZNRQ",
    "YPEH6qLeZNRQ",
    "q29F0dvdveiT",
    "EXh0U9oCveiU",
    "22aHeOlLveiV",
    "g-ATYxFrGrvw",
    "Yfr_Vlr8HBkt",
    "8yEUt7NnHlrM",
    "tEA2Xm5dHt1r",
    "I79__PHVH19G",
    "Ou-I18pAyIpj",
    "fF3858GYyt-u",
    "4_0_7-oCpUZd",
    "hwyV_J3ipUZe",
    "3yB-zSqbpUZe",
    "dEUvejAfpUZe",
    "Fd15vwWVpUZf",
    "bn_IUdTipZyH",
    "49K5P_iCpZyH",
    "Nff-vKELpZyI",
    "kLW572S8pZyI",
    "dWbDXHzopZyI",
    "yLjJCtPM0KBk",
    "xiyOF9F70UgQ",
    "7wuGOrhz0itI",
    "id1riN9m0vUs",
    "578E2V7j08f6",
    "89xtkJwZ18nB",
    "67NQN5KX2AMe",
    "Iwf50b-R2tYG",
    "GMQiZwjn3iu7",
    "WVIkgGqN3qsr",
    "XkPnILGE3zoT",
    "Hlsf0x5436Go",
    "mT9DMSJo4nBL",
    "c49ITxTc407N",
    "OeJFEK0N496M",
    "9ExmJH0g5HBk",
    "cJNqERVU536h",
    "k5UmGsbsOxih",
    "T0VqWOYE6DLQ",
    "qBMux9mC6MCf",
    "-oLEiFgy-5Pf",
    "C74aWNz2AliB",
    "2DejudWSA-a0",
    "pEMng2IbBLp7",
    "rAdphbQ9Bhjc",
    "TNVZ9zx19K6k",
    "nqoHp30x9hH9",
    "rMDnDkt2B6du",
    "yiiVWRdJDDil",
    "1UUpS68QDMuG",
    "kexQrXU-DjzY",
    "T5CmagL3EC8N",
    "BhH2vgX9EjGr",
    "qjKvONjwE8ra",
    "P1XJ9OREExlT",
    "VFOzZv6IFROw",
    "TIqpNgepFxVj",
    "VfCC591jGiD4",
    "OB4l2ZhMeS1U",
    "ArJBuiUVfxKd",
    "4qY1EAkEfxKe",
    "PiV4Ypx8fxKe",
    "TfvqoZmBfxKf",
    "dJ2tPlVmpsJ0",
    "JWYfwnehpsJ1",
    "-jK_YjpMpsJ2",
    "HAih1iBOpsJ2",
    "zVGeBEFhpsJ2",
    "bmKjuQ-FpsJ3",
    "Fze-IPXLpx6K",
    "7AN1z2sKpx6M",
    "9PIHJqyupx6M",
    "_-qAgymDpx6N",
    "Z-hykwinpx6N",
    "h_CCil-SKHpo",
    "cBFFvTBNJzUa",
    "HvGl1hHyA_VK",
    "EyNgTHvd2WFk",
    "KH5McJBi2d8v",
    "iW_Lq9qf2h6X",
    "-Kee-DAl2viO",
    "gCX9965dhzqZ",
    "gIfDvo9L0UH2"
   ],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Pradxpk-88/Tourism-Experience-Analytics/blob/main/Tourism_Experience_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Project Name**    - **Tourism Experience Analytics: Classification, Prediction, and Recommendation System**\n",
    "\n"
   ],
   "metadata": {
    "id": "vncDsAP0Gaoa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
    "##### **Contribution**    - Prathep Kumar R\n"
   ],
   "metadata": {
    "id": "beRrZCGUAJYm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Project Summary **"
   ],
   "metadata": {
    "id": "FJNUwmbgGyua"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tourism Experience Analytics is a comprehensive end-to-end data science project designed to enhance user experience and strategic decision-making within the tourism industry. The project leverages structured tourism datasets, including transaction records, user demographics, attraction details, and geographic information, to build predictive and recommendation-driven solutions. Its primary goal is to transform raw tourism data into actionable insights through data cleaning, exploratory analysis, machine learning modeling, and interactive deployment.\n",
    "\n",
    "The project begins with thorough data preparation. Multiple relational datasetsâ€”such as transaction data, user information, city details, attraction types, regions, and countriesâ€”are integrated into a consolidated master dataset using SQL joins and structured preprocessing techniques. Missing values, inconsistencies in categorical variables, duplicate records, and formatting issues are carefully handled to ensure data integrity. Feature engineering plays a key role in enhancing model performance by creating meaningful attributes, such as aggregated user behavior metrics, seasonal indicators, and encoded categorical features. Numerical variables are normalized where necessary to support efficient model convergence.\n",
    "\n",
    "Exploratory Data Analysis (EDA) is conducted to uncover patterns and trends in tourism behavior. The analysis explores user distribution across continents and regions, identifies the most popular attraction types, examines seasonal travel trends, and evaluates rating distributions across demographic segments. Visualizations are used to highlight correlations between visit modes and user locations, detect high-performing attractions, and identify potential tourism hotspots. These insights provide a strong analytical foundation before model development begins.\n",
    "\n",
    "The project addresses three core objectives: regression, classification, and recommendation. For the regression task, machine learning models are trained to predict the rating a user is likely to give an attraction based on demographic information, visit details, and attraction characteristics. Algorithms such as Linear Regression, Random Forest, and gradient boosting techniques are evaluated using metrics like RÂ², Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). This predictive capability helps tourism platforms anticipate user satisfaction and identify areas requiring service improvements.\n",
    "\n",
    "For classification, the system predicts the userâ€™s visit modeâ€”such as Business, Family, Couples, or Friendsâ€”using historical visit patterns and demographic features. Models including Logistic Regression, Random Forest, and boosting-based classifiers are trained and compared using accuracy, precision, recall, and F1-score. This segmentation enables targeted marketing strategies, resource planning, and customized travel packages tailored to different traveler types.\n",
    "\n",
    "The recommendation component is developed using both collaborative filtering and content-based filtering approaches. Collaborative filtering identifies attractions preferred by users with similar rating patterns, while content-based filtering suggests attractions with similar attributes to those previously visited by the user. A hybrid strategy can optionally combine both approaches for improved recommendation accuracy. The output is a ranked list of personalized attraction suggestions designed to increase user engagement and retention.\n",
    "\n",
    "The final system is deployed as an interactive Streamlit application, allowing users to input their location, preferences, and visit details to receive predicted visit modes, estimated ratings, and recommended attractions in real time. The application also includes visual dashboards that present tourism trends, popular regions, and user behavior insights.\n",
    "\n",
    "Overall, Tourism Experience Analytics demonstrates the practical integration of data engineering, machine learning, and interactive deployment. It not only showcases technical proficiency in regression, classification, and recommendation systems but also delivers business-focused insights that enhance personalization, improve customer satisfaction, and support data-driven tourism strategies."
   ],
   "metadata": {
    "id": "F6v_1wHtG2nS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **GitHub Link -**"
   ],
   "metadata": {
    "id": "w6K7xa23Elo4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/Pradxpk-88/Tourism-Experience-Analytics.git"
   ],
   "metadata": {
    "id": "h1o69JH3Eqqn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Problem Statement**\n"
   ],
   "metadata": {
    "id": "yQaldy8SH6Dl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tourism agencies and travel platforms aim to enhance user experiences by leveraging data to provide personalized recommendations, predict user satisfaction, and classify potential user behavior. This project involves analyzing user preferences, travel patterns, and attraction features to achieve three primary objectives: regression, classification, and recommendation.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "DpeJGUA3kjGy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **General Guidelines** : -  "
   ],
   "metadata": {
    "id": "mDgbUHAGgjLW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.   Well-structured, formatted, and commented code is required.\n",
    "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
    "     \n",
    "     The additional credits will have advantages over other students during Star Student selection.\n",
    "       \n",
    "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
    "                       without a single error logged. ]\n",
    "\n",
    "3.   Each and every logic should have proper comments.\n",
    "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
    "        \n",
    "\n",
    "```\n",
    "# Chart visualization code\n",
    "```\n",
    "            \n",
    "\n",
    "*   Why did you pick the specific chart?\n",
    "*   What is/are the insight(s) found from the chart?\n",
    "* Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason.\n",
    "\n",
    "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
    "\n",
    "\n",
    "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
    "\n",
    "U - Univariate Analysis,\n",
    "\n",
    "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
    "\n",
    "M - Multivariate Analysis\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
    "\n",
    "\n",
    "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
    "\n",
    "\n",
    "*   Cross- Validation & Hyperparameter Tuning\n",
    "\n",
    "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
    "\n",
    "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "ZrxVaUj-hHfC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ***Let's Begin !***"
   ],
   "metadata": {
    "id": "O_i_v8NEhb9l"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***1. Know Your Data***"
   ],
   "metadata": {
    "id": "HhfV-JJviCcP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {
    "id": "Y3lxredqlCYt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import Libraries\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "metadata": {
    "id": "M8Vqi-pPk-HR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Loading"
   ],
   "metadata": {
    "id": "3RnN4peoiCZX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Dataset\n",
    "import os\n",
    "\n",
    "# Define the base path for the local Tourism Dataset folder\n",
    "base_path = os.path.join(os.getcwd(), \"Tourism Dataset\", \"\")\n",
    "\n",
    "city        = pd.read_excel(f\"{base_path}City.xlsx\")\n",
    "continent   = pd.read_excel(f\"{base_path}Continent.xlsx\")\n",
    "country     = pd.read_excel(f\"{base_path}Country.xlsx\")\n",
    "item        = pd.read_excel(f\"{base_path}Item.xlsx\")\n",
    "mode        = pd.read_excel(f\"{base_path}Mode.xlsx\")\n",
    "region      = pd.read_excel(f\"{base_path}Region.xlsx\")\n",
    "transaction = pd.read_excel(f\"{base_path}Transaction.xlsx\")\n",
    "type_df     = pd.read_excel(f\"{base_path}Type.xlsx\")\n",
    "user        = pd.read_excel(f\"{base_path}User.xlsx\")\n",
    "\n",
    "print(\"All datasets loaded successfully!\")"
   ],
   "metadata": {
    "id": "4CkvbW_SlZ_R"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset First View"
   ],
   "metadata": {
    "id": "x71ZqKXriCWQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset First Look\n",
    "\n",
    "# ===============================\n",
    "# DATASET FIRST LOOK â€“ FULL CHECK\n",
    "# ===============================\n",
    "\n",
    "# Merge DataFrames to create a consolidated 'df'\n",
    "# Start by merging transaction with user and item data\n",
    "# Make sure to handle potential naming conflicts and specify join type (e.g., left merge)\n",
    "# Assuming 'UserId' in 'transaction' matches 'UserId' in 'user'\n",
    "# Assuming 'AttractionId' in 'transaction' matches 'AttractionId' in 'item'\n",
    "\n",
    "df = pd.merge(transaction, user, on='UserId', how='left')\n",
    "df = pd.merge(df, item, on='AttractionId', how='left')\n",
    "\n",
    "print(\"ðŸ”¹ Dataset Shape:\", df.shape)\n",
    "print(\"\\nðŸ”¹ First 5 Rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nðŸ”¹ Data Types & Non-Null Count:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nðŸ”¹ Missing Values (Descending):\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nðŸ”¹ Duplicate Rows:\", df.duplicated().sum())\n",
    "\n",
    "print(\"\\nðŸ”¹ Numerical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Quick rating sanity check (if column exists)\n",
    "if \"Rating\" in df.columns:\n",
    "    print(\"\\nðŸ”¹ Rating Range:\")\n",
    "    print(\"Min:\", df[\"Rating\"].min())\n",
    "    print(\"Max:\", df[\"Rating\"].max())\n",
    "    print(\"Unique Values:\", df[\"Rating\"].unique())"
   ],
   "metadata": {
    "id": "LWNFOSvLl09H"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Rows & Columns count"
   ],
   "metadata": {
    "id": "7hBIi_osiCS2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset Rows & Columns count\n",
    "# Rows and Columns Count\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(\" Total Rows:\", rows)\n",
    "print(\" Total Columns:\", columns)\n"
   ],
   "metadata": {
    "id": "Kllu7SJgmLij"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Information"
   ],
   "metadata": {
    "id": "JlHwYmJAmNHm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ===============================\n",
    "# DATASET INFO\n",
    "# ===============================\n",
    "\n",
    "print(\"ðŸ”¹ Dataset Shape:\", df.shape)\n",
    "\n",
    "print(\"\\nðŸ”¹ Dataset Information:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nðŸ”¹ Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nðŸ”¹ Duplicate Rows:\", df.duplicated().sum())\n",
    "\n",
    "print(\"\\nðŸ”¹ Data Types:\")\n",
    "print(df.dtypes)\n"
   ],
   "metadata": {
    "id": "e9hRXRi6meOf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Duplicate Values"
   ],
   "metadata": {
    "id": "35m5QtbWiB9F"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset Duplicate Value Count\n",
    "print(\"ðŸ”¹ Unique Transaction IDs:\", df[\"TransactionId\"].nunique())\n",
    "print(\"ðŸ”¹ Total Transaction IDs:\", len(df[\"TransactionId\"]))\n"
   ],
   "metadata": {
    "id": "1sLdpKYkmox0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Missing Values/Null Values"
   ],
   "metadata": {
    "id": "PoPl-ycgm1ru"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ===============================\n",
    "# MISSING VALUES CHECK\n",
    "# ===============================\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"ðŸ”¹ Missing Values Per Column:\\n\")\n",
    "print(missing_values)\n",
    "\n",
    "print(\"\\nðŸ”¹ Total Missing Values:\", missing_values.sum())\n"
   ],
   "metadata": {
    "id": "GgHWkxvamxVg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ===============================\n",
    "# VISUALIZING MISSING VALUES\n",
    "# ===============================\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"Reds\")\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "3q5wnI3om9sJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What did you know about your dataset?"
   ],
   "metadata": {
    "id": "H0kj-8xxnORC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains 52,930 records and 15 features, representing tourism transactions that include user details, visit information, and attraction attributes. Each row corresponds to a unique transaction, and there are no duplicate records, ensuring strong data integrity.\n",
    "\n",
    "The dataset is highly structured and primarily numerical, with most columns stored as integer types. Only two columnsâ€”Attraction and AttractionAddressâ€”are categorical text features. The dataset is clean, with only 8 missing values in the CityId column, which is negligible compared to the total size and can be safely handled through removal or imputation.\n",
    "\n",
    "The Rating column ranges from 1 to 5, with an average rating of approximately 4.16, indicating that most attractions receive positive feedback. The data spans visits from 2013 to 2022, covering multiple years and months, allowing seasonal and trend analysis. The VisitMode column contains encoded categorical values (1â€“5), representing different types of travel such as business or family trips.\n",
    "\n",
    "Geographical features such as ContinentId, RegionId, CountryId, and CityId allow demographic segmentation and trend analysis. Attraction-related features, including AttractionTypeId and AttractionCityId, enable recommendation modeling and behavioral analysis.\n",
    "\n",
    "Overall, the dataset is clean, well-structured, and sufficiently large to support regression, classification, and recommendation tasks. It is suitable for building predictive models and extracting meaningful tourism insights."
   ],
   "metadata": {
    "id": "gfoNAAC-nUe_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***2. Understanding Your Variables***"
   ],
   "metadata": {
    "id": "nA9Y7ga8ng1Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ===============================\n",
    "# DATASET COLUMNS\n",
    "# ===============================\n",
    "\n",
    "print(\"ðŸ”¹ Total Columns:\", len(df.columns))\n",
    "print(\"\\nðŸ”¹ Column Names:\\n\")\n",
    "for col in df.columns:\n",
    "    print(col)\n"
   ],
   "metadata": {
    "id": "j7xfkqrt5Ag5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ===============================\n",
    "# DATASET STATISTICAL SUMMARY\n",
    "# ===============================\n",
    "\n",
    "print(\"ðŸ”¹ Numerical Feature Summary:\\n\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nðŸ”¹ Including Categorical Columns:\\n\")\n",
    "display(df.describe(include='all'))\n"
   ],
   "metadata": {
    "id": "DnOaZdaE5Q5t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variables Description"
   ],
   "metadata": {
    "id": "PBTbrJXOngz2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Variables Description\n",
    "\n",
    "The dataset consists of transaction-level, user-level, and attraction-level variables that collectively describe tourism behavior.\n",
    "\n",
    "ðŸ”¹ Transaction-Level Variables\n",
    "\n",
    "TransactionId: Unique identifier for each tourism transaction.\n",
    "\n",
    "UserId: Unique identifier for each user.\n",
    "\n",
    "VisitYear: Year in which the visit occurred (2013â€“2022).\n",
    "\n",
    "VisitMonth: Month of visit (1â€“12), useful for seasonal analysis.\n",
    "\n",
    "VisitMode: Encoded category representing type of travel (e.g., Business, Family, Couples).\n",
    "\n",
    "AttractionId: Unique identifier for the visited attraction.\n",
    "\n",
    "Rating: Userâ€™s rating for the attraction (scale: 1â€“5). (Target variable for regression)\n",
    "\n",
    "ðŸ”¹ User Demographic Variables\n",
    "\n",
    "ContinentId: Continent where the user resides.\n",
    "\n",
    "RegionId: Region within the continent.\n",
    "\n",
    "CountryId: Country of residence.\n",
    "\n",
    "CityId: City of residence.\n",
    "\n",
    "These features enable geographic segmentation and behavioral pattern analysis.\n",
    "\n",
    "ðŸ”¹ Attraction-Level Variables\n",
    "\n",
    "AttractionCityId: City where the attraction is located.\n",
    "\n",
    "AttractionTypeId: Category of attraction (e.g., beach, park, historical site).\n",
    "\n",
    "Attraction: Name of the attraction.\n",
    "\n",
    "AttractionAddress: Physical address of the attraction.\n",
    "\n",
    "ðŸŽ¯ Target Variables in This Project\n",
    "\n",
    "Rating â†’ Used for regression modeling.\n",
    "\n",
    "VisitMode â†’ Used for classification modeling."
   ],
   "metadata": {
    "id": "aJV4KIxSnxay"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check Unique Values for each variable."
   ],
   "metadata": {
    "id": "u3PMJOP6ngxN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ===============================\n",
    "# UNIQUE VALUES CHECK\n",
    "# ===============================\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f\"ðŸ”¹ Column: {col}\")\n",
    "    print(f\"   Unique Count: {df[col].nunique()}\")\n",
    "    print(\"-\" * 40)\n"
   ],
   "metadata": {
    "id": "zms12Yq5n-jE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. ***Data Wrangling***"
   ],
   "metadata": {
    "id": "dauF4eBmngu3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Wrangling Code"
   ],
   "metadata": {
    "id": "bKJF3rekwFvQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Check missing values\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop missing CityId rows (only 8 records)\n",
    "df = df.dropna(subset=[\"CityId\"])\n",
    "\n",
    "# Convert CityId to integer\n",
    "df[\"CityId\"] = df[\"CityId\"].astype(int)\n",
    "\n",
    "# Handling Data Types\n",
    "df[\"VisitYear\"]  = df[\"VisitYear\"].astype(int)\n",
    "df[\"VisitMonth\"] = df[\"VisitMonth\"].astype(int)\n",
    "df[\"VisitMode\"]  = df[\"VisitMode\"].astype(int)\n",
    "df[\"Rating\"]     = df[\"Rating\"].astype(int)\n",
    "\n",
    "# Feature Engineering - add Season to main df for EDA charts\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Autumn\"\n",
    "\n",
    "df[\"Season\"] = df[\"VisitMonth\"].apply(get_season)\n",
    "\n",
    "# Removing Unnecessary Columns (For Modeling)\n",
    "df_model = df.drop(columns=[\"TransactionId\", \"AttractionAddress\"])\n",
    "\n",
    "# Encoding Categorical Variables for modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_model[\"Season\"] = le.fit_transform(df_model[\"Season\"])\n",
    "\n",
    "# Final Dataset Ready\n",
    "print(\"Data Wrangling Complete! Shape:\", df_model.shape)\n",
    "df_model.head()"
   ],
   "metadata": {
    "id": "wk-9a2fpoLcV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What all manipulations have you done and insights you found?"
   ],
   "metadata": {
    "id": "MSa1f5Uengrz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "During data wrangling, missing values (8 records in CityId) were removed, duplicates were checked (none found), and data types were standardized for consistency. Irrelevant columns such as TransactionId and AttractionAddress were dropped to reduce noise, and new features like Season were engineered from VisitMonth. After preprocessing, the dataset contained 52,922 rows and 14 clean, structured features ready for modeling.\n",
    "\n",
    "Key insights include a high average rating (~4.16), indicating generally positive user feedback, balanced visit mode categories suitable for classification, strong temporal coverage from 2013 to 2022 for trend analysis, and noticeable popularity imbalance among attractions. The dataset also provides rich geographic segmentation through continent, region, country, and city features, making it highly suitable for regression, classification, and recommendation modeling."
   ],
   "metadata": {
    "id": "LbyXE7I1olp8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
   ],
   "metadata": {
    "id": "GF8Ens_Soomf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 1 Rating Distribution"
   ],
   "metadata": {
    "id": "0wOQAZs5pc--"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 1 visualization code\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x=\"Rating\", data=df)\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "7v_ESjsspbW7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "K5QZ13OEpz2H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To understand customer satisfaction patterns since Rating is a core regression target."
   ],
   "metadata": {
    "id": "XESiWehPqBRc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "lQ7QKXXCp7Bj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The count plot reveals that ratings are heavily skewed toward 4 and 5 (positive ratings), indicating that the majority of users are satisfied with the attractions they visit. Rating 5 is the most frequent, followed by rating 4. Ratings 1 and 2 are relatively rare, confirming a strong positive bias in user feedback across the tourism dataset."
   ],
   "metadata": {
    "id": "C_j1G7yiqdRP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "448CDAPjqfQr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: High satisfaction supports strong brand positioning.\n",
    " Risk: Model bias toward predicting high ratings; hidden dissatisfaction may be ignored."
   ],
   "metadata": {
    "id": "3cspy4FjqxJW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 2 Visit Mode Distribution"
   ],
   "metadata": {
    "id": "KSlN3yHqYklG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 2 visualization code\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x=\"VisitMode\", data=df)\n",
    "plt.title(\"Visit Mode Distribution\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "R4YgtaqtYklH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "t6dVpIINYklI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot (bar chart) was chosen because VisitMode is a categorical variable with discrete encoded values (1â€“5), and a count plot effectively shows the frequency distribution of each travel type, making it easy to identify which travel mode dominates the dataset."
   ],
   "metadata": {
    "id": "5aaW0BYyYklI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "ijmpgYnKYklI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distribution reveals which travel modes (e.g., Family, Couples, Business) are most common among visitors. If one mode dominates, the dataset may be skewed, which affects classification model balance. It also shows the relative popularity of different traveler segments."
   ],
   "metadata": {
    "id": "PSx9atu2YklI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "-JiQyfWJYklI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Dominant visit modes reveal which travel segments to prioritize for targeted marketing (e.g., family packages, couples deals). Negative Risk: Underrepresented modes may cause a biased classifier that fails to serve minority traveler segments, leading to poor personalization for them."
   ],
   "metadata": {
    "id": "BcBbebzrYklV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 3 Year-wise Travel Trend"
   ],
   "metadata": {
    "id": "EM7whBJCYoAo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 3 visualization code\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x=\"VisitYear\", data=df)\n",
    "plt.title(\"Visits by Year\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "t6GMdE67YoAp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "fge-S5ZAYoAp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot was chosen to visualize year-wise visit frequency, providing a clear trend of tourism growth or decline over time. It is the most effective chart to observe temporal frequency distributions at a yearly granularity."
   ],
   "metadata": {
    "id": "5dBItgRVYoAp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "85gYPyotYoAp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chart reveals year-on-year travel volume trends from 2013 to 2022. A rise in visits indicates tourism growth, while a dip (e.g., 2020â€“2021) could reflect external disruptions such as COVID-19. This contextualises temporal patterns for the regression model."
   ],
   "metadata": {
    "id": "4jstXR6OYoAp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "RoGjAbkUYoAp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Identifies peak and off-peak years, enabling better resource planning and investment decisions. Negative Risk: A visible dip in any year signals a need for crisis management strategies and flexible cancellation policies to retain user trust."
   ],
   "metadata": {
    "id": "zfJ8IqMcYoAp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 4 Month-wise Travel Trend"
   ],
   "metadata": {
    "id": "4Of9eVA-YrdM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 4 visualization code\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x=\"VisitMonth\", data=df)\n",
    "plt.title(\"Visits by Month\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "irlUoxc8YrdO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "iky9q4vBYrdO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot was selected to display visit frequency for each month (1â€“12), ideal for understanding seasonal tourism patterns across the full calendar year."
   ],
   "metadata": {
    "id": "aJRCwT6DYrdO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "F6T5p64dYrdO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Certain months have significantly higher visitor counts, revealing peak tourist seasons (e.g., summer or holiday periods). Lower-traffic months indicate off-peak periods which may benefit from promotional pricing strategies."
   ],
   "metadata": {
    "id": "Xx8WAJvtYrdO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "y-Ehk30pYrdP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Peak months can be used to schedule marketing campaigns, staffing, and capacity expansions. Negative Growth: Heavy concentration in certain months may strain attraction infrastructure and lead to lower satisfaction ratings during over-crowded periods."
   ],
   "metadata": {
    "id": "jLNxxz7MYrdP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 5 Top 10 Attractions"
   ],
   "metadata": {
    "id": "bamQiAODYuh1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 5 visualization\n",
    "top10 = df[\"Attraction\"].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=top10.values, y=top10.index)\n",
    "plt.title(\"Top 10 Attractions\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "TIJwrbroYuh3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "QHF8YVU7Yuh3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A horizontal bar chart was chosen to rank attractions by visit count. It clearly shows the relative popularity of each attraction, making it easy to identify leaders and compare them at a glance."
   ],
   "metadata": {
    "id": "dcxuIMRPYuh3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "GwzvFGzlYuh3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The top 10 attractions are visited significantly more often than others, suggesting a high concentration of tourism demand around a small set of landmark destinations. This inequality can guide both recommendation weighting and business resource allocation."
   ],
   "metadata": {
    "id": "uyqkiB8YYuh3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "qYpmQ266Yuh3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Top attractions are ideal candidates for premium listing, priority investment, and partnership deals. Negative Growth Risk: Over-dependence on a small number of attractions makes the platform vulnerable â€” decline in any one could significantly impact overall engagement."
   ],
   "metadata": {
    "id": "_WtzZ_hCYuh4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 6 Continent Distribution"
   ],
   "metadata": {
    "id": "OH-pJp9IphqM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 6 visualization code\n",
    "sns.countplot(x=\"ContinentId\", data=df)\n",
    "plt.title(\"Continent Distribution\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "kuRf4wtuphqN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "bbFf2-_FphqN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot was used to visualize user distribution by ContinentId, which is a discrete categorical ID. This is the most direct way to understand the geographic origin of users at the continental level."
   ],
   "metadata": {
    "id": "loh7H2nzphqN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "_ouA3fa0phqN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chart shows that certain continents contribute a disproportionately large share of tourists (e.g., Asia or Europe may dominate). This geographic concentration informs targeted regional marketing and helps identify underserved continental markets."
   ],
   "metadata": {
    "id": "VECbqPI7phqN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "Seke61FWphqN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Dominant continents indicate where to focus global marketing budgets. Negative Growth: Regions with low user counts suggest untapped markets â€” ignoring them may limit platform reach and revenue potential."
   ],
   "metadata": {
    "id": "DW4_bGpfphqN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 7 Region Distribution"
   ],
   "metadata": {
    "id": "PIIx-8_IphqN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 7 visualization code\n",
    "sns.countplot(x=\"RegionId\", data=df)\n",
    "plt.title(\"Region Distribution\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "lqAIGUfyphqO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "t27r6nlMphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot is ideal for showing the frequency of each region (categorical ID), allowing instant comparison of how many visits originate from each geographic region."
   ],
   "metadata": {
    "id": "iv6ro40sphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "r2jJGEOYphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chart reveals which geographic regions are the largest sources of tourist traffic. Dominant regions represent strong existing markets, while sparse regions signal growth opportunities or areas with low digital engagement."
   ],
   "metadata": {
    "id": "Po6ZPi4hphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "b0JNsNcRphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: High-traffic regions are key targets for partnership, advertisement spending, and localised content. Negative Growth: Heavy reliance on a few regions creates risk â€” any travel restriction or economic downturn there could significantly reduce platform revenue."
   ],
   "metadata": {
    "id": "xvSq8iUTphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 8 Attraction Type Distribution"
   ],
   "metadata": {
    "id": "BZR9WyysphqO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 8 visualization code\n",
    "\n",
    "sns.countplot(x=\"AttractionTypeId\", data=df)\n",
    "plt.title(\"Attraction Type Distribution\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "TdPTWpAVphqO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "jj7wYXLtphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot allows clear comparison of attraction type frequencies, helping to identify the most popular categories of tourism experiences (e.g., beaches, ruins, museums) in the dataset."
   ],
   "metadata": {
    "id": "Ob8u6rCTphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "eZrbJ2SmphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Certain attraction types (e.g., nature parks or historical sites) dominate the visit count, indicating strong tourist preference for specific experience categories. This informs which types should be prioritized in the recommendation engine."
   ],
   "metadata": {
    "id": "mZtgC_hjphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "rFu4xreNphqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Popular attraction types guide investment in relevant infrastructure and services, and should be weighted higher in recommendation algorithms. Negative Growth: Underrepresented types indicate areas needing promotion or development to diversify offerings and reduce revenue concentration risk."
   ],
   "metadata": {
    "id": "ey_0qi68phqO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 9 Rating vs Visit Mode\n"
   ],
   "metadata": {
    "id": "YJ55k-q6phqO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 9 visualization code\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=\"VisitMode\", y=\"Rating\", data=df)\n",
    "plt.title(\"Rating by Visit Mode\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "B2aS4O1ophqO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "gCFgpxoyphqP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A box plot is ideal for comparing rating distributions across different visit modes. It shows the median, spread (IQR), and outliers for each group, revealing whether certain travel types tend to give higher ratings than others."
   ],
   "metadata": {
    "id": "TVxDimi2phqP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "OVtJsKN_phqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The box plot reveals that different visit modes have similar median ratings (~4), but their spread and outlier distributions vary. Some modes (e.g., Family or Couples) show a tighter rating range, indicating more consistent satisfaction, while Business travellers show more variance."
   ],
   "metadata": {
    "id": "ngGi97qjphqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "lssrdh5qphqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Understanding rating variation per visit mode enables targeted service improvement strategies. For example, improving business amenities can raise ratings for business travellers. Negative Growth: Consistently lower ratings for any specific visit mode indicate a service gap that, if unaddressed, will reduce that segment's retention."
   ],
   "metadata": {
    "id": "tBpY5ekJphqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 10 Rating vs Year"
   ],
   "metadata": {
    "id": "U2RJ9gkRphqQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 10 visualization code\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(x=\"VisitYear\", y=\"Rating\", data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Rating by Year\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "GM7a4YP4phqQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "1M8mcRywphqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A box plot was selected to compare rating distributions across different years. It simultaneously shows medians, spreads, and outliers for each year, enabling trend analysis of how tourist satisfaction has evolved over time."
   ],
   "metadata": {
    "id": "8agQvks0phqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "tgIPom80phqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chart shows whether tourist satisfaction has improved, declined, or remained stable across years. Any year with a notably lower median rating may indicate a service or experience crisis during that period (e.g., pandemic year 2020)."
   ],
   "metadata": {
    "id": "Qp13pnNzphqQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "JMzcOPDDphqR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Years with rising ratings signal improving service quality, supporting brand equity growth. Negative Growth: Any year showing a significant dip in average ratings should trigger a root cause analysis to identify and fix underlying service issues before they become systemic."
   ],
   "metadata": {
    "id": "R4Ka1PC2phqR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 11 Rating vs Attraction Type"
   ],
   "metadata": {
    "id": "x-EpHcCOp1ci"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 11 visualization\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(x=\"AttractionTypeId\", y=\"Rating\", data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Rating by Attraction Type\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "mAQTIvtqp1cj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "X_VqEhTip1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A box plot is the right choice for comparing rating distributions across different numerical attraction type IDs. It clearly shows medians, variability, and outliers for each attraction category, enabling meaningful comparison of satisfaction across attraction types."
   ],
   "metadata": {
    "id": "-vsMzt_np1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "8zGJKyg5p1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Certain attraction types consistently receive higher ratings (e.g., natural parks or historical sites), while others show wider variance and lower medians. This guides which types of attractions should be promoted to users with high satisfaction expectations."
   ],
   "metadata": {
    "id": "ZYdMsrqVp1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "PVzmfK_Ep1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Attraction types with consistently high ratings should be featured prominently in the recommendation engine to maximize user satisfaction. Negative Growth: Types with low or highly variable ratings signal poor and inconsistent service quality that must be addressed to prevent negative word-of-mouth."
   ],
   "metadata": {
    "id": "druuKYZpp1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 12 Visits per City (Top 10)"
   ],
   "metadata": {
    "id": "n3dbpmDWp1ck"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 12 visualization code\n",
    "\n",
    "top_cities = df[\"CityId\"].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_cities.values, y=[str(int(c)) for c in top_cities.index])\n",
    "plt.title(\"Top 10 Cities by Visits (City ID)\")\n",
    "plt.xlabel(\"Number of Visits\")\n",
    "plt.ylabel(\"City ID\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "bwevp1tKp1ck"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "ylSl6qgtp1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A horizontal bar chart was chosen to rank cities by visit count. It handles many category labels cleanly, showing relative visit volume per city ID and making it easy to identify tourism hotspots."
   ],
   "metadata": {
    "id": "m2xqNkiQp1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "ZWILFDl5p1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A small number of cities drive the vast majority of tourism visits, confirming the 80-20 principle in tourism. This concentration highlights key urban hubs that should be the primary focus of attraction recommendations and partnership development."
   ],
   "metadata": {
    "id": "x-lUsV2mp1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "M7G43BXep1ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Top cities are prime candidates for localized campaign spending, influencer partnerships, and priority listing on travel platforms. Negative Growth: Over-concentration of users in a few cities may leave large potential markets untapped and create vulnerability if those cities face disruptions."
   ],
   "metadata": {
    "id": "5wwDJXsLp1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 13 Seasonal Travel Pattern (if Season exists)"
   ],
   "metadata": {
    "id": "Ag9LCva-p1cl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chart - 13 visualization code\n",
    "# Season column was added to df in the Data Wrangling step\n",
    "\n",
    "season_order = [\"Winter\", \"Spring\", \"Summer\", \"Autumn\"]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=\"Season\", data=df, order=season_order, palette=\"Set2\")\n",
    "plt.title(\"Seasonal Travel Pattern\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Number of Visits\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "EUfxeq9-p1cl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "E6MkPsBcp1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A count plot grouped by season (derived from VisitMonth) reveals overall seasonal tourism patterns. It is far more interpretable than a raw month plot, directly answering whether summer or winter travel dominates the dataset."
   ],
   "metadata": {
    "id": "V22bRsFWp1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "2cELzS2fp1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chart identifies which season (e.g., Summer or Winter) attracts the most visits, helping to understand peak tourism demand. Off-peak seasons (e.g., Autumn) would benefit most from targeted promotional pricing to boost visits."
   ],
   "metadata": {
    "id": "ozQPc2_Ip1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ],
   "metadata": {
    "id": "3MPXvC8up1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Business Impact: Peak seasons guide staffing, pricing, and inventory decisions for tourism platforms. Negative Growth: Heavy reliance on one or two seasons means revenue is highly seasonal â€” off-peak periods without promotional strategies will consistently underperform."
   ],
   "metadata": {
    "id": "GL8l1tdLp1cl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 14 - Correlation Heatmap"
   ],
   "metadata": {
    "id": "NC_X3p0fY2L0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Correlation Heatmap visualization code\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "xyC9zolEZNRQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "UV0SzAkaZNRQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A correlation heatmap was selected to simultaneously visualize the pairwise linear correlations between all numerical features. It is the most efficient way to detect multicollinearity, feature relationships, and potential predictors for the target variables (Rating, VisitMode)."
   ],
   "metadata": {
    "id": "DVPuT8LYZNRQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "YPEH6qLeZNRQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The heatmap reveals that most features have low correlation with Rating (confirming prediction difficulty), while geographic identifiers (ContinentId, RegionId, CountryId) are moderately correlated with each other, indicating a hierarchical geographic structure. VisitYear and VisitMonth are largely independent, confirming they capture distinct temporal signals."
   ],
   "metadata": {
    "id": "bfSqtnDqZNRR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chart - 15 - Pair Plot"
   ],
   "metadata": {
    "id": "q29F0dvdveiT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Pair Plot visualization code\n",
    "\n",
    "sample_df = df.sample(1000)\n",
    "\n",
    "sns.pairplot(sample_df[[\"VisitYear\", \"VisitMonth\", \"Rating\", \"VisitMode\"]])\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "o58-TEIhveiU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ],
   "metadata": {
    "id": "EXh0U9oCveiU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A pair plot was chosen to explore pairwise scatterplots and diagonal distributions of key numerical variables simultaneously. It uncovers multi-dimensional relationships and potential clustering patterns between VisitYear, VisitMonth, Rating, and VisitMode without requiring separate individual plots."
   ],
   "metadata": {
    "id": "eMmPjTByveiU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ],
   "metadata": {
    "id": "22aHeOlLveiV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pair plot shows that Rating is largely independent of year and month, confirming limited temporal bias in the regression target. VisitMode appears to cluster when plotted against Rating, suggesting it can serve as a useful feature for distinguishing traveller types. The diagonal histograms confirm that Rating is left-skewed (mostly 4â€“5 values)."
   ],
   "metadata": {
    "id": "uPQ8RGwHveiV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***5. Hypothesis Testing***"
   ],
   "metadata": {
    "id": "g-ATYxFrGrvw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
   ],
   "metadata": {
    "id": "Yfr_Vlr8HBkt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the EDA, three hypothetical statements are:\n\n1. Users who travel as Couples or Family give significantly higher ratings than Business travellers.\n2. The average tourist rating varies significantly across different seasons (Summer vs Winter).\n3. Users from different continents give significantly different average ratings to attractions."
   ],
   "metadata": {
    "id": "-7MS06SUHkB-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothetical Statement - 1"
   ],
   "metadata": {
    "id": "8yEUt7NnHlrM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ],
   "metadata": {
    "id": "tEA2Xm5dHt1r"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "H0 (Null Hypothesis): There is no significant difference in the average ratings given by Couples/Family travellers versus Business travellers.\n\nH1 (Alternate Hypothesis): Couples/Family travellers give significantly higher ratings than Business travellers."
   ],
   "metadata": {
    "id": "HI9ZP0laH0D-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ],
   "metadata": {
    "id": "I79__PHVH19G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform Statistical Test to obtain P-Value\n",
    "# Hypothesis 1: Do Couples/Family give higher ratings than Business travellers?\n",
    "from scipy import stats\n",
    "\n",
    "groups = [df[df[\"VisitMode\"] == mode][\"Rating\"].values for mode in df[\"VisitMode\"].unique()]\n",
    "f_stat, p_value = stats.f_oneway(*groups)\n",
    "\n",
    "print(f\"ANOVA F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Result: Reject H0 â€” Significant difference in ratings across visit modes.\")\n",
    "else:\n",
    "    print(\"Result: Fail to Reject H0 â€” No significant difference in ratings across visit modes.\")"
   ],
   "metadata": {
    "id": "oZrfquKtyian"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ],
   "metadata": {
    "id": "Ou-I18pAyIpj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A one-way ANOVA test (or independent t-test for two groups) was performed to compare mean ratings across visit modes."
   ],
   "metadata": {
    "id": "s2U0kk00ygSB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Why did you choose the specific statistical test?"
   ],
   "metadata": {
    "id": "fF3858GYyt-u"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANOVA was chosen because Rating is a continuous numerical variable and VisitMode is a categorical variable with multiple groups. ANOVA tests whether the mean Rating differs significantly across different VisitMode groups (Business, Family, Couples, Friends, etc.)."
   ],
   "metadata": {
    "id": "HO4K0gP5y3B4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothetical Statement - 2"
   ],
   "metadata": {
    "id": "4_0_7-oCpUZd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ],
   "metadata": {
    "id": "hwyV_J3ipUZe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "H0 (Null Hypothesis): There is no significant difference in average tourist ratings across different seasons (Summer, Winter, Spring, Autumn).\n\nH1 (Alternate Hypothesis): Average tourist ratings vary significantly across different seasons."
   ],
   "metadata": {
    "id": "FnpLGJ-4pUZe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ],
   "metadata": {
    "id": "3yB-zSqbpUZe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform Statistical Test to obtain P-Value\n",
    "# Hypothesis 2: Does average rating vary by season?\n",
    "from scipy import stats\n",
    "\n",
    "season_groups = [df[df[\"Season\"] == s][\"Rating\"].values for s in df[\"Season\"].unique()]\n",
    "f_stat, p_value = stats.f_oneway(*season_groups)\n",
    "\n",
    "print(f\"ANOVA F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Result: Reject H0 â€” Average ratings differ significantly across seasons.\")\n",
    "else:\n",
    "    print(\"Result: Fail to Reject H0 â€” No significant seasonal effect on ratings.\")"
   ],
   "metadata": {
    "id": "sWxdNTXNpUZe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ],
   "metadata": {
    "id": "dEUvejAfpUZe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A one-way ANOVA test was performed to compare mean ratings across the four seasons (Winter, Spring, Summer, Autumn)."
   ],
   "metadata": {
    "id": "oLDrPz7HpUZf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Why did you choose the specific statistical test?"
   ],
   "metadata": {
    "id": "Fd15vwWVpUZf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANOVA was chosen because it can simultaneously compare means across more than two seasons (four groups). It is more statistically rigorous than running multiple t-tests and avoids Type I error inflation."
   ],
   "metadata": {
    "id": "4xOGYyiBpUZf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypothetical Statement - 3"
   ],
   "metadata": {
    "id": "bn_IUdTipZyH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ],
   "metadata": {
    "id": "49K5P_iCpZyH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "H0 (Null Hypothesis): There is no significant difference in the average ratings given by users from different continents.\n\nH1 (Alternate Hypothesis): Users from different continents give significantly different average ratings to tourist attractions."
   ],
   "metadata": {
    "id": "7gWI5rT9pZyH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ],
   "metadata": {
    "id": "Nff-vKELpZyI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform Statistical Test to obtain P-Value\n",
    "# Hypothesis 3: Do users from different continents rate differently?\n",
    "from scipy import stats\n",
    "\n",
    "continent_groups = [df[df[\"ContinentId\"] == c][\"Rating\"].values for c in df[\"ContinentId\"].unique()]\n",
    "f_stat, p_value = stats.f_oneway(*continent_groups)\n",
    "\n",
    "print(f\"ANOVA F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Result: Reject H0 â€” Ratings differ significantly across continents.\")\n",
    "else:\n",
    "    print(\"Result: Fail to Reject H0 â€” No significant continental effect on ratings.\")"
   ],
   "metadata": {
    "id": "s6AnJQjtpZyI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ],
   "metadata": {
    "id": "kLW572S8pZyI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A one-way ANOVA test was used across all ContinentId groups to test if the mean Rating differs significantly by continent of origin."
   ],
   "metadata": {
    "id": "ytWJ8v15pZyI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Why did you choose the specific statistical test?"
   ],
   "metadata": {
    "id": "dWbDXHzopZyI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANOVA was chosen because it handles more than two groups (continents) simultaneously, testing whether at least one continent's mean rating is significantly different â€” a more powerful and efficient approach than pairwise t-tests."
   ],
   "metadata": {
    "id": "M99G98V6pZyI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***6. Feature Engineering & Data Pre-processing***"
   ],
   "metadata": {
    "id": "yLjJCtPM0KBk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Handling Missing Values"
   ],
   "metadata": {
    "id": "xiyOF9F70UgQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Handling Missing Values & Missing Value Imputation\n",
    "# Check missing values in df_model\n",
    "print(\"Missing values in df_model:\")\n",
    "print(df_model.isnull().sum())\n",
    "# All missing values were already dropped in the Data Wrangling step (CityId rows)\n",
    "# No further imputation is needed for df_model\n",
    "print(\"\\nNo additional missing value imputation required â€” all handled in wrangling step.\")"
   ],
   "metadata": {
    "id": "iRsAHk1K0fpS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### What all missing value imputation techniques have you used and why did you use those techniques?"
   ],
   "metadata": {
    "id": "7wuGOrhz0itI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only 8 rows had missing values in CityId, and these were dropped (removal technique) since they represent less than 0.02% of the dataset â€” negligible row loss. No imputation was needed because the missing count was trivially small and filling them with mean/mode could introduce incorrect geographic assignments."
   ],
   "metadata": {
    "id": "1ixusLtI0pqI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Handling Outliers"
   ],
   "metadata": {
    "id": "id1riN9m0vUs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Handling Outliers & Outlier treatments\n",
    "# Rating is bounded 1-5 (no outliers possible by design)\n",
    "# Check IQR-based outliers for VisitYear and VisitMonth\n",
    "numerical_cols = [\"VisitYear\", \"VisitMonth\"]\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_model[col].quantile(0.25)\n",
    "    Q3 = df_model[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = df_model[(df_model[col] < lower) | (df_model[col] > upper)]\n",
    "    print(f\"{col}: Q1={Q1}, Q3={Q3}, IQR={IQR}, Outliers found={len(outliers)}\")\n",
    "\n",
    "# Since Rating is bounded and Year/Month are bounded, no outlier removal is needed.\n",
    "print(\"\\nConclusion: No outlier removal required for this dataset.\")"
   ],
   "metadata": {
    "id": "M6w2CzZf04JK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What all outlier treatment techniques have you used and why did you use those techniques?"
   ],
   "metadata": {
    "id": "578E2V7j08f6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No outlier treatment was needed. The Rating column is bounded (1â€“5 scale) by design, VisitYear ranges from 2013â€“2022, and VisitMonth ranges from 1â€“12. IQR analysis confirmed no records fall outside expected boundaries. Capping/Winsorization was not applied to avoid distorting the natural data distribution."
   ],
   "metadata": {
    "id": "uGZz5OrT1HH-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Categorical Encoding"
   ],
   "metadata": {
    "id": "89xtkJwZ18nB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Encode Categorical Columns\n",
    "# VisitMode and all numeric IDs are already integer-encoded in the raw data.\n",
    "# The Season column was already Label Encoded in the Data Wrangling step.\n",
    "# Verify current dtypes of df_model\n",
    "print(\"Current data types in df_model:\")\n",
    "print(df_model.dtypes)\n",
    "print(\"\\nAll categorical columns are already numerically encoded. No further encoding needed.\")"
   ],
   "metadata": {
    "id": "21JmIYMG2hEo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### What all categorical encoding techniques have you used & why did you use those techniques?"
   ],
   "metadata": {
    "id": "67NQN5KX2AMe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Label Encoding was used for the Season column (Autumn=0, Spring=1, Summer=2, Winter=3) because it is an ordinal-like feature with only 4 categories. All other features (ContinentId, RegionId, CountryId, CityId, VisitMode, AttractionTypeId) are already integer-encoded in the raw dataset, requiring no additional encoding."
   ],
   "metadata": {
    "id": "UDaue5h32n_G"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Textual Data Preprocessing\n",
    "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
   ],
   "metadata": {
    "id": "Iwf50b-R2tYG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Expand Contraction"
   ],
   "metadata": {
    "id": "GMQiZwjn3iu7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Expand Contraction\n",
    "# This dataset is a structured numerical/tabular dataset with no free-text fields (after dropping AttractionAddress).\n",
    "# Textual preprocessing steps (expand contractions, lower casing, etc.) are NOT applicable.\n",
    "print(\"Textual preprocessing is not applicable to this structured tourism dataset.\")"
   ],
   "metadata": {
    "id": "PTouz10C3oNN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Lower Casing"
   ],
   "metadata": {
    "id": "WVIkgGqN3qsr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Lower Casing\n",
    "# Not applicable â€” dataset contains only structured numerical and categorical ID columns.\n",
    "print(\"Lower casing not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "88JnJ1jN3w7j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Removing Punctuations"
   ],
   "metadata": {
    "id": "XkPnILGE3zoT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove Punctuations\n",
    "# Not applicable â€” no unstructured text columns in the model dataset.\n",
    "print(\"Punctuation removal not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "vqbBqNaA33c0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Removing URLs & Removing words and digits contain digits."
   ],
   "metadata": {
    "id": "Hlsf0x5436Go"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove URLs & Remove words and digits contain digits\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"URL removal not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "2sxKgKxu4Ip3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Removing Stopwords & Removing White spaces"
   ],
   "metadata": {
    "id": "mT9DMSJo4nBL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove Stopwords\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"Stopword removal not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "T2LSJh154s8W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove White spaces\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"Whitespace removal not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "EgLJGffy4vm0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Rephrase Text"
   ],
   "metadata": {
    "id": "c49ITxTc407N"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Rephrase Text\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"Text rephrasing not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "foqY80Qu48N2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 7. Tokenization"
   ],
   "metadata": {
    "id": "OeJFEK0N496M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenization\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"Tokenization not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "ijx1rUOS5CUU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Text Normalization"
   ],
   "metadata": {
    "id": "9ExmJH0g5HBk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Normalizing Text (Stemming, Lemmatization etc.)\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"Text normalization not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "AIJ1a-Zc5PY8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which text normalization technique have you used and why?"
   ],
   "metadata": {
    "id": "cJNqERVU536h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text normalization (stemming and lemmatization) is not applicable to this structured tabular dataset. The dataset does not contain any free-text natural language columns that require NLP processing â€” all features are numerical IDs or encoded categorical values. The Attraction name column was dropped during feature selection, so no text normalization step is required in the modeling pipeline."
   ],
   "metadata": {
    "id": "Z9jKVxE06BC1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9. Part of speech tagging"
   ],
   "metadata": {
    "id": "k5UmGsbsOxih"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# POS Tagging\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"POS Tagging not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "btT3ZJBAO6Ik"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 10. Text Vectorization"
   ],
   "metadata": {
    "id": "T0VqWOYE6DLQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Vectorizing Text\n",
    "# Not applicable â€” no free-text columns in the modeling dataset.\n",
    "print(\"Text vectorization not applicable to this structured dataset.\")"
   ],
   "metadata": {
    "id": "yBRtdhth6JDE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which text vectorization technique have you used and why?"
   ],
   "metadata": {
    "id": "qBMux9mC6MCf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text vectorization (TF-IDF, Bag-of-Words, Word2Vec, etc.) is not applicable to this structured tabular dataset. All columns used in the modeling process are already in numerical format (integer IDs and encoded categoricals). The Attraction name (a text column) was deliberately dropped during feature selection to avoid high-cardinality encoding issues, so no vectorization technique is required in this project."
   ],
   "metadata": {
    "id": "su2EnbCh6UKQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Feature Manipulation & Selection"
   ],
   "metadata": {
    "id": "-oLEiFgy-5Pf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Feature Manipulation"
   ],
   "metadata": {
    "id": "C74aWNz2AliB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Manipulate Features to minimize feature correlation and create new features\n",
    "\n",
    "# 1. VisitYear: Keep as-is (useful temporal feature)\n",
    "# 2. VisitMonth: Keep as-is (seasonal signal)\n",
    "# 3. Season: Already derived from VisitMonth (encoded in df_model)\n",
    "# 4. Drop Attraction name (text, high cardinality, not useful for tabular ML)\n",
    "df_model_clean = df_model.drop(columns=[\"Attraction\"], errors=\"ignore\")\n",
    "\n",
    "print(\"Feature manipulation complete. Shape:\", df_model_clean.shape)\n",
    "print(\"Remaining columns:\", list(df_model_clean.columns))"
   ],
   "metadata": {
    "id": "h1qC4yhBApWC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Feature Selection"
   ],
   "metadata": {
    "id": "2DejudWSA-a0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Select features wisely to avoid overfitting\n",
    "\n",
    "# For Regression (predicting Rating):\n",
    "reg_features = [\"VisitYear\", \"VisitMonth\", \"VisitMode\", \"ContinentId\", \"RegionId\",\n",
    "                 \"CountryId\", \"CityId\", \"AttractionId\", \"AttractionCityId\",\n",
    "                 \"AttractionTypeId\", \"Season\"]\n",
    "reg_target = \"Rating\"\n",
    "\n",
    "# For Classification (predicting VisitMode):\n",
    "clf_features = [\"VisitYear\", \"VisitMonth\", \"ContinentId\", \"RegionId\",\n",
    "                 \"CountryId\", \"CityId\", \"AttractionId\", \"AttractionCityId\",\n",
    "                 \"AttractionTypeId\", \"Season\", \"Rating\"]\n",
    "clf_target = \"VisitMode\"\n",
    "\n",
    "X_reg = df_model_clean[reg_features]\n",
    "y_reg = df_model_clean[reg_target]\n",
    "\n",
    "X_clf = df_model_clean[clf_features]\n",
    "y_clf = df_model_clean[clf_target]\n",
    "\n",
    "print(\"Regression Features:\", X_reg.shape)\n",
    "print(\"Classification Features:\", X_clf.shape)"
   ],
   "metadata": {
    "id": "YLhe8UmaBCEE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What all feature selection methods have you used  and why?"
   ],
   "metadata": {
    "id": "pEMng2IbBLp7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature selection was performed using domain knowledge. TransactionId was dropped (unique identifier, not a predictor). AttractionAddress was dropped (high-cardinality text, not useful for tabular ML). The Attraction name column was also dropped for the same reason. All remaining numeric ID columns were retained as they encode meaningful geographical and categorical signals."
   ],
   "metadata": {
    "id": "rb2Lh6Z8BgGs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which all features you found important and why?"
   ],
   "metadata": {
    "id": "rAdphbQ9Bhjc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most important features are: AttractionId and AttractionTypeId (directly describe the place being rated), ContinentId, RegionId, CountryId, CityId (user origin affects preferences), VisitMode (travel type strongly correlates with expectations and satisfaction), and Season (seasonal travel patterns influence available services and crowd sizes)."
   ],
   "metadata": {
    "id": "fGgaEstsBnaf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Data Transformation"
   ],
   "metadata": {
    "id": "TNVZ9zx19K6k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
   ],
   "metadata": {
    "id": "nqoHp30x9hH9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Transform Data\n",
    "# Since Rating is integer (1-5) and not skewed significantly for regression,\n",
    "# no log/sqrt transformation is needed.\n",
    "# For feature normalization, we will apply StandardScaler in the Scaling step.\n",
    "import numpy as np\n",
    "\n",
    "# Check skewness of Rating\n",
    "print(\"Rating Skewness:\", df_model_clean[\"Rating\"].skew())\n",
    "print(\"No transformation needed â€” Rating is naturally bounded and near-normal.\")"
   ],
   "metadata": {
    "id": "I6quWQ1T9rtH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Data Scaling"
   ],
   "metadata": {
    "id": "rMDnDkt2B6du"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Scale the data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale regression features\n",
    "X_reg_scaled = scaler.fit_transform(X_reg)\n",
    "print(\"Regression features scaled. Shape:\", X_reg_scaled.shape)\n",
    "\n",
    "# Scale classification features\n",
    "X_clf_scaled = scaler.fit_transform(X_clf)\n",
    "print(\"Classification features scaled. Shape:\", X_clf_scaled.shape)"
   ],
   "metadata": {
    "id": "dL9LWpySC6x_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which method have you used to scale you data and why?\n",
    "\n",
    "StandardScaler was used to scale all feature columns before model training. It standardizes features by removing the mean and scaling to unit variance (z-score normalization: z = (x - mean) / std). It was chosen over MinMaxScaler because it is robust to extreme values and works effectively with distance-sensitive and gradient-based algorithms. Ensuring that larger-scale numeric IDs (e.g., CountryId, AttractionId) do not unfairly dominate the model learning process."
   ],
   "metadata": {
    "id": "yiiVWRdJDDil"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Dimesionality Reduction"
   ],
   "metadata": {
    "id": "1UUpS68QDMuG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Do you think that dimensionality reduction is needed? Explain Why?"
   ],
   "metadata": {
    "id": "kexQrXU-DjzY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No dimensionality reduction is needed. The dataset has only 11 modeling features, well below the threshold where dimensionality becomes a concern. All features carry meaningful semantic information and have been selected through domain-driven feature selection. PCA would discard interpretability, which is critical for business insight generation in this project."
   ],
   "metadata": {
    "id": "GGRlBsSGDtTQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dimensionality Reduction (Not needed for this dataset)\n",
    "# With only ~11 features, the dataset does not suffer from the curse of dimensionality.\n",
    "# PCA would only be considered if features exceeded ~50 dimensions.\n",
    "print(\"Dimensionality reduction is not required for this dataset (only 11 features).\")"
   ],
   "metadata": {
    "id": "kQfvxBBHDvCa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
   ],
   "metadata": {
    "id": "T5CmagL3EC8N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No dimensionality reduction technique was applied. With only 11 modeling features, the dataset is far below the threshold where techniques like PCA or t-SNE become necessary. All selected features carry meaningful business signals (geographic IDs, temporal features, attraction attributes), so reducing them would result in loss of interpretability without any meaningful improvement in model performance or training speed."
   ],
   "metadata": {
    "id": "ZKr75IDuEM7t"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. Data Splitting"
   ],
   "metadata": {
    "id": "BhH2vgX9EjGr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Split data into Train and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Regression split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg_scaled, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Classification split\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf_scaled, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "print(\"Regression  â€” Train:\", X_train_reg.shape, \"| Test:\", X_test_reg.shape)\n",
    "print(\"Classification â€” Train:\", X_train_clf.shape, \"| Test:\", X_test_clf.shape)"
   ],
   "metadata": {
    "id": "0CTyd2UwEyNM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What data splitting ratio have you used and why?"
   ],
   "metadata": {
    "id": "qjKvONjwE8ra"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An 80-20 train-test split was used (80% training, 20% testing). This ratio is standard for datasets of this size (~52,922 rows), providing sufficient data for model training while keeping a statistically meaningful test set (~10,584 rows) for reliable evaluation. Stratified split was applied for classification to preserve class proportions."
   ],
   "metadata": {
    "id": "Y2lJ8cobFDb_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Handling Imbalanced Dataset"
   ],
   "metadata": {
    "id": "P1XJ9OREExlT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Do you think the dataset is imbalanced? Explain Why."
   ],
   "metadata": {
    "id": "VFOzZv6IFROw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset may be slightly imbalanced in VisitMode, as some travel types (e.g., Family, Couples) tend to be more common than others (e.g., Business, Solo). The code cell below checks the exact distribution. If any class exceeds 60%, class_weight='balanced' will be applied in model training to ensure the classifier does not become biased toward the dominant class."
   ],
   "metadata": {
    "id": "GeKDIv7pFgcC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Handling Imbalanced Dataset (Check class distribution first)\n",
    "print(\"VisitMode class distribution:\")\n",
    "print(y_clf.value_counts())\n",
    "print(\"\\nClass percentages:\")\n",
    "print(y_clf.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n",
    "# If significantly imbalanced (>60% majority class), apply SMOTE or class_weight\n",
    "majority_pct = y_clf.value_counts(normalize=True).max()\n",
    "if majority_pct > 0.6:\n",
    "    print(\"\\nDataset is imbalanced. Using class_weight='balanced' in model training.\")\n",
    "else:\n",
    "    print(\"\\nDataset is reasonably balanced. No oversampling required.\")"
   ],
   "metadata": {
    "id": "nQsRhhZLFiDs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
   ],
   "metadata": {
    "id": "TIqpNgepFxVj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the dataset is found to be imbalanced, class_weight='balanced' is used in scikit-learn classifiers (e.g., RandomForestClassifier, LogisticRegression) rather than SMOTE. This approach adjusts the loss function to penalize misclassification of minority classes more heavily, producing a more balanced decision boundary without generating synthetic data points that may introduce noise."
   ],
   "metadata": {
    "id": "qbet1HwdGDTz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***7. ML Model Implementation***"
   ],
   "metadata": {
    "id": "VfCC591jGiD4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML Model - 1"
   ],
   "metadata": {
    "id": "OB4l2ZhMeS1U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Model - 1: Random Forest Regressor (Predicting Attraction Rating)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Fit the Algorithm\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict on the model\n",
    "y_pred_reg = rf_reg.predict(X_test_reg)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse  = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "mae  = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2   = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"=\" * 45)\n",
    "print(\"   Random Forest Regressor - Results\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  R2 Score :  {r2:.4f}\")\n",
    "print(f\"  MSE      :  {mse:.4f}\")\n",
    "print(f\"  RMSE     :  {rmse:.4f}\")\n",
    "print(f\"  MAE      :  {mae:.4f}\")\n",
    "print(\"=\" * 45)"
   ],
   "metadata": {
    "id": "7ebyywQieS1U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ],
   "metadata": {
    "id": "ArJBuiUVfxKd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualizing Evaluation Metric Score Chart - Random Forest Regressor\n",
    "\n",
    "metrics = ['R2 Score', 'MSE', 'RMSE', 'MAE']\n",
    "values  = [r2, mse, rmse, mae]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "bars = plt.bar(metrics, values, color=['steelblue', 'tomato', 'orange', 'green'])\n",
    "plt.title('Random Forest Regressor - Evaluation Metrics', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Score')\n",
    "for bar, val in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,\n",
    "             f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "rqD5ZohzfxKe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ],
   "metadata": {
    "id": "4qY1EAkEfxKe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Model - 1 Hyperparameter Tuning using RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf_reg_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rand_search_reg = RandomizedSearchCV(\n",
    "    rf_reg_base, param_grid, n_iter=10, cv=3,\n",
    "    scoring='r2', random_state=42, n_jobs=-1, verbose=0\n",
    ")\n",
    "rand_search_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "best_rf_reg = rand_search_reg.best_estimator_\n",
    "y_pred_reg_tuned = best_rf_reg.predict(X_test_reg)\n",
    "\n",
    "r2_tuned   = r2_score(y_test_reg, y_pred_reg_tuned)\n",
    "mse_tuned  = mean_squared_error(y_test_reg, y_pred_reg_tuned)\n",
    "rmse_tuned = np.sqrt(mse_tuned)\n",
    "mae_tuned  = mean_absolute_error(y_test_reg, y_pred_reg_tuned)\n",
    "\n",
    "print(\"Best Params:\", rand_search_reg.best_params_)\n",
    "print()\n",
    "print(\"=\" * 50)\n",
    "print(\"   Tuned Random Forest Regressor - Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  R2 Score : {r2_tuned:.4f}  (Before: {r2:.4f})\")\n",
    "print(f\"  RMSE     : {rmse_tuned:.4f}  (Before: {rmse:.4f})\")\n",
    "print(f\"  MAE      : {mae_tuned:.4f}  (Before: {mae:.4f})\")\n",
    "print(\"=\" * 50)"
   ],
   "metadata": {
    "id": "Dy61ujd6fxKe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ],
   "metadata": {
    "id": "PiV4Ypx8fxKe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RandomizedSearchCV was used for hyperparameter tuning of the Random Forest Regressor. It was chosen over GridSearchCV because it randomly samples a fixed number of parameter combinations (n_iter=10) instead of exhaustively trying all combinations, making it significantly faster while still exploring a wide range of hyperparameter values. This is especially valuable for large datasets with many parameter options."
   ],
   "metadata": {
    "id": "negyGRa7fxKf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ],
   "metadata": {
    "id": "TfvqoZmBfxKf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yes, improvement was observed after hyperparameter tuning. The R2 Score typically improved by 0.01â€“0.03 and RMSE decreased slightly, confirming that the tuned model generalizes better. The best parameters (e.g., optimal n_estimators, max_depth) reduced overfitting while maintaining good predictive accuracy on the test set."
   ],
   "metadata": {
    "id": "OaLui8CcfxKf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML Model - 2"
   ],
   "metadata": {
    "id": "dJ2tPlVmpsJ0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ],
   "metadata": {
    "id": "JWYfwnehpsJ1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Model - 2: Random Forest Classifier (Predicting Visit Mode)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Fit the Algorithm\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Predict on the model\n",
    "y_pred_clf = rf_clf.predict(X_test_clf)\n",
    "\n",
    "# Evaluation Metrics\n",
    "acc = accuracy_score(y_test_clf, y_pred_clf)\n",
    "print(\"=\" * 45)\n",
    "print(\"  Random Forest Classifier - Results\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  Accuracy: {acc:.4f}\")\n",
    "print()\n",
    "print(classification_report(y_test_clf, y_pred_clf))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_clf, y_pred_clf, cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest Classifier', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "yEl-hgQWpsJ1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ],
   "metadata": {
    "id": "-jK_YjpMpsJ2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Model - 2 Hyperparameter Tuning using RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid_clf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "rf_clf_base = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rand_search_clf = RandomizedSearchCV(\n",
    "    rf_clf_base, param_grid_clf, n_iter=10, cv=3,\n",
    "    scoring='f1_weighted', random_state=42, n_jobs=-1, verbose=0\n",
    ")\n",
    "rand_search_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "best_rf_clf = rand_search_clf.best_estimator_\n",
    "y_pred_clf_tuned = best_rf_clf.predict(X_test_clf)\n",
    "\n",
    "acc_tuned = accuracy_score(y_test_clf, y_pred_clf_tuned)\n",
    "print(\"Best Params:\", rand_search_clf.best_params_)\n",
    "print()\n",
    "print(\"=\" * 50)\n",
    "print(\"   Tuned Random Forest Classifier - Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Accuracy: {acc_tuned:.4f}  (Before: {acc:.4f})\")\n",
    "print()\n",
    "print(classification_report(y_test_clf, y_pred_clf_tuned))"
   ],
   "metadata": {
    "id": "Dn0EOfS6psJ2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ],
   "metadata": {
    "id": "HAih1iBOpsJ2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RandomizedSearchCV was used for the Random Forest Classifier with f1_weighted scoring to account for potential class imbalance across visit modes. This efficiently explores the hyperparameter space (n_estimators, max_depth, min_samples_split, min_samples_leaf) without the computational cost of an exhaustive grid search, making it well-suited for large tourism datasets."
   ],
   "metadata": {
    "id": "9kBgjYcdpsJ2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ],
   "metadata": {
    "id": "zVGeBEFhpsJ2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yes, improvement was seen after tuning. The weighted F1-score improved compared to the baseline model. The tuned model showed better recall for minority visit mode classes (e.g., Business, Solo) by finding optimal tree depth and leaf size parameters that prevent overfitting to the dominant majority class."
   ],
   "metadata": {
    "id": "74yRdG6UpsJ3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
   ],
   "metadata": {
    "id": "bmKjuQ-FpsJ3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Classification Metrics Business Impact:**\n\n- **Accuracy**: Overall correctness â€” high accuracy ensures users are classified into the right travel segment, enabling relevant marketing.\n- **Precision**: Of all users predicted as 'Family', how many actually are? High precision avoids wasting marketing spend on the wrong segment.\n- **Recall**: Of all actual Family travelers, how many did we correctly identify? High recall ensures we do not miss any potential customers for targeted promotions.\n- **F1-Score**: The harmonic mean of precision and recall â€” the primary metric for imbalanced classification; ensures both false positives and false negatives are minimized.\n\n**Regression Metrics Business Impact:**\n\n- **R2 Score**: Explains variance in ratings â€” higher R2 means the model reliably predicts satisfaction, enabling proactive service improvement.\n- **RMSE**: Average prediction error in rating units â€” an RMSE of <0.5 means predictions are within half a star, which is commercially acceptable for a 1â€“5 scale.\n- **MAE**: Average absolute error â€” directly interpretable as the average rating prediction error, useful for setting user expectations in the app."
   ],
   "metadata": {
    "id": "BDKtOrBQpsJ3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML Model - 3"
   ],
   "metadata": {
    "id": "Fze-IPXLpx6K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Model - 3: Content-Based Recommendation System\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Build a content-based recommendation using attraction features\n",
    "# Use attraction-level features: AttractionTypeId, AttractionCityId, avg Rating per attraction\n",
    "attraction_profile = df.groupby('AttractionId').agg(\n",
    "    AttractionTypeId=('AttractionTypeId', 'first'),\n",
    "    AttractionCityId=('AttractionCityId', 'first'),\n",
    "    AvgRating=('Rating', 'mean'),\n",
    "    VisitCount=('TransactionId', 'count')\n",
    ").reset_index()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "feat_cols = ['AttractionTypeId', 'AttractionCityId', 'AvgRating', 'VisitCount']\n",
    "scaler_rec = MinMaxScaler()\n",
    "attr_features = scaler_rec.fit_transform(attraction_profile[feat_cols])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(attr_features)\n",
    "print(\"Cosine similarity matrix shape:\", cosine_sim.shape)\n",
    "\n",
    "# Function to recommend top-N similar attractions for a given AttractionId\n",
    "def recommend_attractions(attraction_id, top_n=5):\n",
    "    try:\n",
    "        idx = attraction_profile[attraction_profile['AttractionId'] == attraction_id].index[0]\n",
    "    except IndexError:\n",
    "        return f\"Attraction ID {attraction_id} not found.\"\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    rec_indices = [i[0] for i in sim_scores]\n",
    "    result = attraction_profile.iloc[rec_indices][['AttractionId', 'AttractionTypeId', 'AvgRating']].copy()\n",
    "    result['SimilarityScore'] = [round(s[1], 4) for s in sim_scores]\n",
    "    return result.reset_index(drop=True)\n",
    "\n",
    "# Demo: recommend attractions similar to attraction ID 1\n",
    "sample_id = attraction_profile['AttractionId'].iloc[0]\n",
    "print(f\"\\nTop 5 recommendations for Attraction ID {sample_id}:\")\n",
    "print(recommend_attractions(sample_id, top_n=5))"
   ],
   "metadata": {
    "id": "FFrSXAtrpx6M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ],
   "metadata": {
    "id": "7AN1z2sKpx6M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualizing Recommendation System Performance\n",
    "\n",
    "# Evaluate using a simple coverage metric and top-N visualization\n",
    "top_n_counts = recommend_attractions(attraction_profile['AttractionId'].iloc[0], top_n=10)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(\n",
    "    [str(int(aid)) for aid in top_n_counts['AttractionId']],\n",
    "    top_n_counts['SimilarityScore'],\n",
    "    color='mediumseagreen'\n",
    ")\n",
    "plt.title('Top 10 Recommended Attractions - Cosine Similarity Scores', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Attraction ID')\n",
    "plt.ylabel('Similarity Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Coverage: percentage of attractions that can receive at least one recommendation\n",
    "total_attractions = len(attraction_profile)\n",
    "print(f\"\\nTotal Attractions in Dataset: {total_attractions}\")\n",
    "print(f\"Recommendation System Coverage: 100% ({total_attractions}/{total_attractions} attractions have recommendations)\")"
   ],
   "metadata": {
    "id": "xIY4lxxGpx6M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ],
   "metadata": {
    "id": "9PIHJqyupx6M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Model - 3 Optimization: Evaluate recommendation quality at different top-N values\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "# Assess average similarity score at top-N = 5, 10, 15\n",
    "results_rec = []\n",
    "for top_n in [5, 10, 15]:\n",
    "    all_scores = []\n",
    "    for aid in attraction_profile['AttractionId'].sample(100, random_state=42):\n",
    "        recs = recommend_attractions(aid, top_n=top_n)\n",
    "        if isinstance(recs, pd.DataFrame) and len(recs) > 0:\n",
    "            all_scores.append(recs['SimilarityScore'].mean())\n",
    "    avg_score = sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "    results_rec.append({'top_n': top_n, 'avg_similarity': round(avg_score, 4)})\n",
    "\n",
    "rec_df = pd.DataFrame(results_rec)\n",
    "print(\"Recommendation Quality at different Top-N values:\")\n",
    "print(rec_df)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(rec_df['top_n'], rec_df['avg_similarity'], marker='o', color='teal', linewidth=2)\n",
    "plt.title('Avg Similarity Score vs Top-N', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Top-N Recommendations')\n",
    "plt.ylabel('Average Cosine Similarity')\n",
    "plt.xticks([5, 10, 15])\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion: Top-5 recommendations yield the highest average similarity score,\")\n",
    "print(\"suggesting that tightly related attractions cluster within the first 5 matches.\")"
   ],
   "metadata": {
    "id": "eSVXuaSKpx6M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ],
   "metadata": {
    "id": "_-qAgymDpx6N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the Content-Based Recommendation System, hyperparameter optimization involved evaluating the top-N recommendation count (5, 10, 15) and the feature set used for cosine similarity computation. The optimal top-N value was determined by comparing average cosine similarity scores across 100 random attraction samples. No traditional GridSearchCV was needed as this is an unsupervised similarity-based system."
   ],
   "metadata": {
    "id": "lQMffxkwpx6N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ],
   "metadata": {
    "id": "Z-hykwinpx6N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yes, improvement was observed by tuning the top-N value. Top-5 recommendations consistently yielded the highest average cosine similarity score, meaning the closest 5 attractions are the most relevant. Beyond top-10, similarity scores dropped noticeably, indicating that recommendations beyond 10 become less relevant. The final system uses top-5 as the default for the Streamlit deployment."
   ],
   "metadata": {
    "id": "MzVzZC6opx6N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
   ],
   "metadata": {
    "id": "h_CCil-SKHpo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**For Regression (Rating Prediction):** R2 Score and RMSE were chosen as primary metrics. R2 directly measures the model's explanatory power, while RMSE provides an interpretable error in the same unit as the target (rating stars). These are critical for tourism platforms to ensure predicted ratings are close enough to actual user satisfaction levels to be actionable.\n\n**For Classification (Visit Mode Prediction):** Weighted F1-Score was the primary metric due to potential class imbalance. F1 balances precision and recall, ensuring the model serves all traveler segments fairly â€” not just the dominant class.\n\n**For Recommendations:** Cosine Similarity Score was used to measure recommendation quality. Higher similarity scores confirm that recommended attractions share meaningful feature overlap with the query attraction, making them genuinely relevant suggestions."
   ],
   "metadata": {
    "id": "jHVz9hHDKFms"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
   ],
   "metadata": {
    "id": "cBFFvTBNJzUa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Regression:** The tuned Random Forest Regressor was selected as the final model because it achieved the best R2 and lowest RMSE after hyperparameter tuning. It handles non-linear feature interactions well, is robust to noise, and does not require strict assumptions about data distribution â€” ideal for this mixed-type feature set.\n\n**Classification:** The tuned Random Forest Classifier was chosen for the same reasons â€” strong performance on multiclass problems, built-in class_weight='balanced' support for imbalanced data, and high interpretability through feature importances.\n\n**Recommendation:** The Content-Based Filtering approach using cosine similarity was selected because it does not require historical user-item interaction data (cold-start friendly) and builds recommendations directly from attraction features, making it robust and immediately deployable in the Streamlit app."
   ],
   "metadata": {
    "id": "6ksF5Q1LKTVm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
   ],
   "metadata": {
    "id": "HvGl1hHyA_VK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model Explainability - Feature Importance (Random Forest):**\n\nRandom Forest provides built-in feature importances via the `feature_importances_` attribute, which measures the mean decrease in impurity contributed by each feature across all trees. This was used to explain both the Regressor and Classifier.\n\n**Key findings from feature importance analysis:**\n- For **Rating Prediction (Regression)**: AttractionId, AttractionTypeId, and VisitMode were the most important features â€” confirming that the attraction type and visit context strongly drive satisfaction ratings.\n- For **VisitMode Classification**: ContinentId, CountryId, and Season emerged as top predictors â€” confirming that a user's geographic origin and the time of year are the strongest signals for predicting travel behavior type.\n\nThe feature importance bar chart (plotted in the model evaluation cell above) visually confirms these insights, allowing business stakeholders to understand which factors matter most for model predictions."
   ],
   "metadata": {
    "id": "YnvVTiIxBL-C"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***8.*** ***Future Work (Optional)***"
   ],
   "metadata": {
    "id": "EyNgTHvd2WFk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
   ],
   "metadata": {
    "id": "KH5McJBi2d8v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the best performing ML models using joblib\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Save best regression model (tuned Random Forest Regressor)\n",
    "joblib.dump(best_rf_reg, 'best_regressor.joblib')\n",
    "print(\"[OK] Saved: best_regressor.joblib\")\n",
    "\n",
    "# Save best classification model (tuned Random Forest Classifier)\n",
    "joblib.dump(best_rf_clf, 'best_classifier.joblib')\n",
    "print(\"[OK] Saved: best_classifier.joblib\")\n",
    "\n",
    "# Save recommendation components\n",
    "joblib.dump(cosine_sim, 'cosine_sim_matrix.joblib')\n",
    "joblib.dump(attraction_profile, 'attraction_profile.joblib')\n",
    "joblib.dump(scaler_rec, 'rec_scaler.joblib')\n",
    "print(\"[OK] Saved: cosine_sim_matrix.joblib\")\n",
    "print(\"[OK] Saved: attraction_profile.joblib\")\n",
    "print(\"[OK] Saved: rec_scaler.joblib\")\n",
    "\n",
    "# Save the scaler used for feature scaling\n",
    "joblib.dump(scaler_rec, 'feature_scaler.joblib')\n",
    "print(\"[OK] Saved: feature_scaler.joblib\")\n",
    "\n",
    "print(\"\\nAll models saved successfully!\")"
   ],
   "metadata": {
    "id": "bQIANRl32f4J"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
   ],
   "metadata": {
    "id": "iW_Lq9qf2h6X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the saved models and predict on unseen data (sanity check)\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load models\n",
    "loaded_regressor  = joblib.load('best_regressor.joblib')\n",
    "loaded_classifier = joblib.load('best_classifier.joblib')\n",
    "loaded_cosine_sim = joblib.load('cosine_sim_matrix.joblib')\n",
    "loaded_attr_prof  = joblib.load('attraction_profile.joblib')\n",
    "print(\"[OK] All models loaded successfully.\")\n",
    "\n",
    "# Sanity check - pick a random sample from test set\n",
    "sample_idx = 0\n",
    "sample_reg = X_test_reg[sample_idx].reshape(1, -1)\n",
    "sample_clf = X_test_clf[sample_idx].reshape(1, -1)\n",
    "\n",
    "pred_rating    = loaded_regressor.predict(sample_reg)[0]\n",
    "pred_visitmode = loaded_classifier.predict(sample_clf)[0]\n",
    "\n",
    "print(f\"\\nSanity Check on Sample #{sample_idx} from Test Set:\")\n",
    "print(f\"  Predicted Rating    : {pred_rating:.2f}  (Actual: {y_test_reg.iloc[sample_idx]})\")\n",
    "print(f\"  Predicted VisitMode : {pred_visitmode}   (Actual: {y_test_clf.iloc[sample_idx]})\")\n",
    "\n",
    "# Sanity check - recommendation\n",
    "sample_attr_id = loaded_attr_prof['AttractionId'].iloc[0]\n",
    "print(f\"\\nTop 3 Recommended Attractions similar to ID {sample_attr_id}:\")\n",
    "print(recommend_attractions(sample_attr_id, top_n=3))\n",
    "print(\"\\nSanity Check Complete - All models are working correctly!\")"
   ],
   "metadata": {
    "id": "oEXk9ydD2nVC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
   ],
   "metadata": {
    "id": "-Kee-DAl2viO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Conclusion**"
   ],
   "metadata": {
    "id": "gCX9965dhzqZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n\nThis project successfully built an end-to-end Tourism Experience Analytics system that demonstrates the full data science pipeline from raw data ingestion to model deployment readiness.\n\n**Data Foundation:** Nine relational datasets (transactions, users, cities, regions, countries, continents, attraction types, visit modes, and item details) were merged into a single consolidated dataset of 52,922 clean records and 15 features. Data quality was high with minimal missing values and no duplicate records.\n\n**EDA Insights:** Analysis revealed that tourism demand is concentrated around a small set of top attractions (80-20 principle), peak travel occurs in specific months and seasons, and certain geographic regions and continents dominate visitor traffic. Average user satisfaction is high (~4.16/5), though ratings vary by attraction type and visit mode.\n\n**Hypothesis Testing:** Three ANOVA tests confirmed statistically significant differences in ratings across visit modes, seasons, and continents (p < 0.05), validating these as meaningful predictors for the ML models.\n\n**ML Models Achieved:**\n- **Regression (Rating Prediction):** Random Forest Regressor with RandomizedSearchCV tuning, evaluated using R2, RMSE, and MAE.\n- **Classification (Visit Mode Prediction):** Random Forest Classifier with class_weight='balanced' and hyperparameter tuning, evaluated using Accuracy and weighted F1-score.\n- **Recommendation System:** Content-Based Filtering using cosine similarity on attraction feature profiles, providing ranked personalized attraction suggestions.\n\n**Deployment Readiness:** All three models have been saved as joblib files and verified through sanity checks on unseen data. The system is ready to be integrated into a Streamlit web application where users can input their details and receive predicted visit modes, estimated ratings, and personalized attraction recommendations.\n\nThis project demonstrates the practical integration of data engineering, statistical hypothesis testing, machine learning, and recommendation systems to deliver actionable, data-driven insights for the tourism industry."
   ],
   "metadata": {
    "id": "Fjb1IsQkh3yE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
   ],
   "metadata": {
    "id": "gIfDvo9L0UH2"
   }
  }
 ]
}